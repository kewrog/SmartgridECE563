{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff5d425",
   "metadata": {},
   "source": [
    "#  PROJECT 4 - ARTIFICIAL INTELLIGENCE IN SMART GRID \n",
    "\n",
    "NAME - **ROGER KEWIN SAMSON**\n",
    "\n",
    "\n",
    "HAWK ID - **A20563057**\n",
    "\n",
    "\n",
    "Mail ID: rkewin@hawk.iit.edu\n",
    "\n",
    "\n",
    "**SPRING 2024**\n",
    "\n",
    "\n",
    "Illinois Institute Of Technology\n",
    "\n",
    "                                            Date: MARCH 28 , 2024\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbbd609",
   "metadata": {},
   "source": [
    "# Brief overview of the project:\n",
    "\n",
    "The project focuses on applying these both datasets - Scikit-Learn Breast Cancer dataset, and the Scikit-Learn Diabetes dataset focusing on the Random Forest and Gradient Boosting algorithms. \n",
    "\n",
    "## DATA PREPARATION:\n",
    "1. As per the given procedures first we split the dataset into training / validation (80%) and test (20%) using \" train_test_split\" library with a my own selected random state.\n",
    "2. Then we prepare the second split from the training set from the 80% to training and validation sets, test size = 0.25 of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed120ed",
   "metadata": {},
   "source": [
    "# RANDOM FOREST :\n",
    "\n",
    "This method is used for both classification and regression task. it is used to correct the random forests for decision trees habit of overfitting to thier training set.\n",
    "For classification, the output class is the one that receives the majority vote from individual trees. For regression, it is typically the average of the outputs from all trees.\n",
    "The randomness injected into the model creation process helps prevent overfitting, making Random Forests more robust and accurate than individual decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed2ea4",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING: \n",
    "\n",
    "It is the method used for both regression and classification tasks where to denote the weak prediction of models.Unlike Random Forest, Gradient Boosting builds trees one at a time, where each new tree helps to correct errors made by previously trained trees.\n",
    "\n",
    " It can be used with a variety of loss functions to model different prediction problems, making it a versatile tool for tackling a wide range of data science challenges.Both Random Forest and Gradient Boosting are powerful machine learning algorithms that can handle a wide range of data types and problem statements. While Random Forest aims to reduce variance through bagging, Gradient Boosting focuses on reducing bias through boosting, making them complementary approaches depending on the specific requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2bf3c",
   "metadata": {},
   "source": [
    "# 1(a) Python code that splits the original Wisconsin breast cancer dataset into two subsets: training/validation (80%), and test (20%). Be sure to document how you made the split, including the \"random_state\" value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819d4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation set size: (455, 30) (455,)\n",
      "Test set size: (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training/validation (80%) and test (20%) subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Print the shapes of the splits to verify the sizes\n",
    "print(\"Training/Validation set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d18e7",
   "metadata": {},
   "source": [
    " In this above code we splits the wisconsin breast cancer dataset into two subsets by training/validation (80%)and test (20%)\n",
    "we used the sklearn.diabetes and imported the datasets and train_test_split to split the data and get the output of the shape of  splitted datasets.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890faaa8",
   "metadata": {},
   "source": [
    "# I have used random_state=0. because, I want the consistent value for each repitation while running each time. So, I used \"0\" in the random state value in the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55979e91",
   "metadata": {},
   "source": [
    "# 1(b) Python code that uses an additional split to create a validation dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc3725",
   "metadata": {},
   "source": [
    "I have used the only additional split where the question has been seperated by \"or\". hence i used this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617dbfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (341, 30), (341,)\n",
      "Validation set size: (114, 30), (114,)\n",
      "Test set size: (114, 30), (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# First split: Separate the original dataset into 80% training/validation and 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Second split: Further split the training/validation dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0) # This results in 60% training, 20% validation from the original dataset\n",
    "\n",
    "# Output the sizes of each dataset to verify\n",
    "print(f\"Training set size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019edc7",
   "metadata": {},
   "source": [
    "I have created additional split as continued to the above code.The first split separate the original dataset into 80% training /validation  and 20% test with the random_state = 0. On the next split  60% training, 20% validation from the original dataset\n",
    "with the same random_state=0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945dfe3",
   "metadata": {},
   "source": [
    "# Procedure documenting your design process and the tradeoffs you considered in building a Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b3346a",
   "metadata": {},
   "source": [
    "As we must use the Random forest classifier it will handle both linear and nonlinear relationships.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac4c17",
   "metadata": {},
   "source": [
    "## DATA PREPARATION :\n",
    "\n",
    "•The required libraries are imported from the sklearn for this breast cancer data set used and assigned that datum in the X variable.\n",
    "•The dataset is split using the library into training, validation, and testing. We already split it as 80% training/validation and 20% test and the training set is again split as a second split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae999",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER SELECTION: \n",
    "•“n_estimators” (Number of trees) = 165: the decision to increase the number of trees from the default to improve model accuracy by averaging more decision trees. The tradeoff here is increased computational cost and potentially longer training times.\n",
    "•‘max_depth = 10 ‘ : limiting the depth of trees helps to control the overfitting by preventing the model noisy patterns in training data.\n",
    "•“min_samples_split=4”: Increasing the minimum number of samples required to split a node from  4 makes the model slightly more conservative in growing each tree. The trade-off involves potentially increased bias for slightly reduced variance.\n",
    "•“random_state=0”: Setting a random state ensures that the result is reproducible.\n",
    "Hence I used “0” to control the same randomness and get the same on each repetition to consider when looking for the best split at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef12fe",
   "metadata": {},
   "source": [
    "## MODEL EVALUATION :\n",
    "To check the accuracy score by training, validation, and test datasets provide a straightforward measure of the model's performance. High training accuracy with comparable validation and test accuracies suggests good generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5b123",
   "metadata": {},
   "source": [
    "# Python code that uses RandomForestClassifier to train, validate and test a Random Forest model. You may use any number of features from the dataset. Be sure to set the \"random_state\" so we can recreate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70c6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Performance:\n",
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9561\n",
      "Test Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize the Random Forest Classifier with some hyperparameters adjusted from their default values\n",
    "rf = RandomForestClassifier(n_estimators=165, max_depth=10, min_samples_split=4, random_state=0)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training, validation, and test sets\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_val = rf.predict(X_val)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Output the performance\n",
    "print(\"RandomForestClassifier Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43517cf8",
   "metadata": {},
   "source": [
    "# What could you do to improve the prediction score of your trained model on the validation data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6f0ee",
   "metadata": {},
   "source": [
    "•\tAdjust ‘max_features’ new number of features to consider when looking for the best split. Reducing the max_features helps to improve the model's accuracy.\n",
    "\n",
    "•\tIncrease ‘n_estimators’ the default value is 100 we increased the value is -165 still to improve the score increase the value. But it takes more computational time.\n",
    "\n",
    "•\tUse k-fold cross-validation to ensure the model's robustness across different subsets of the data. This can provide a more accurate estimate of the model's performance and generalization ability.\n",
    "\n",
    "•\tUse feature importance scores from the RandomForestClassifier to identify and retain only the most informative features. Removing irrelevant or noisy features can improve model accuracy.\n",
    "\n",
    "•\tAlthough Random Forest has built-in mechanisms to prevent overfitting, additional regularization techniques or more careful adjustment of the hyperparameters that control model complexity can further mitigate overfitting risks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce1b4e",
   "metadata": {},
   "source": [
    "# How well does your final model predict the classes in the test data? Provide a list of all of the examples from the test data that are predicted incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55aa018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No correctly predicted examples found.\n",
      "Poorly-predicted example index: 0\n",
      "Predicted class: 0.999999948577179, Actual class: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Identify a well-predicted example\n",
    "correctly_predicted_indices = np.where(y_pred_test == y_test)[0]\n",
    "if correctly_predicted_indices.size > 0:\n",
    "    well_predicted_index = correctly_predicted_indices[0]\n",
    "    print(f\"Well-predicted example index: {well_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test[well_predicted_index]}, Actual class: {y_test[well_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No correctly predicted examples found.\")\n",
    "\n",
    "# Identify a poorly-predicted example\n",
    "incorrectly_predicted_indices = np.where(y_pred_test != y_test)[0]\n",
    "if incorrectly_predicted_indices.size > 0:\n",
    "    poorly_predicted_index = incorrectly_predicted_indices[0]\n",
    "    print(f\"Poorly-predicted example index: {poorly_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test[poorly_predicted_index]}, Actual class: {y_test[poorly_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No incorrectly predicted examples found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376928ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Incorrect Predictions: 114\n",
      "Listing Incorrectly Predicted Examples:\n",
      "Index: 0, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 1, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 2, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 3, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 4, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 5, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 6, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 7, Predicted Class: 0.19906166105411705, Actual Class: 0\n",
      "Index: 8, Predicted Class: 0.35279422881945927, Actual Class: 1\n",
      "Index: 9, Predicted Class: 0.9236645119118571, Actual Class: 1\n",
      "Index: 10, Predicted Class: 0.6803999485771791, Actual Class: 1\n",
      "Index: 11, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 12, Predicted Class: 1.0069133077481627, Actual Class: 1\n",
      "Index: 13, Predicted Class: 0.08100006087268094, Actual Class: 0\n",
      "Index: 14, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 15, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 16, Predicted Class: 1.0136299343193145, Actual Class: 1\n",
      "Index: 17, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 18, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 19, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 20, Predicted Class: 0.999999948577179, Actual Class: 0\n",
      "Index: 21, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 22, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 23, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 24, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 25, Predicted Class: 0.9999999486155152, Actual Class: 1\n",
      "Index: 26, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 27, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 28, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 29, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 30, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 31, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 32, Predicted Class: 0.7606400115763537, Actual Class: 1\n",
      "Index: 33, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 34, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 35, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 36, Predicted Class: 0.07290008550699421, Actual Class: 0\n",
      "Index: 37, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 38, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 39, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 40, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 41, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 42, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 43, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 44, Predicted Class: 0.6560999486155151, Actual Class: 1\n",
      "Index: 45, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 46, Predicted Class: 0.6821229344339297, Actual Class: 1\n",
      "Index: 47, Predicted Class: 0.8999999485771791, Actual Class: 1\n",
      "Index: 48, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 49, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 50, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 51, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 52, Predicted Class: 0.9099999485771791, Actual Class: 1\n",
      "Index: 53, Predicted Class: 0.9999999486155152, Actual Class: 1\n",
      "Index: 54, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 55, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 56, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 57, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 58, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 59, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 60, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 61, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 62, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 63, Predicted Class: 0.7013897353427921, Actual Class: 1\n",
      "Index: 64, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 65, Predicted Class: 0.7289999485771791, Actual Class: 1\n",
      "Index: 66, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 67, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 68, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 69, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 70, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 71, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 72, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 73, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 74, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 75, Predicted Class: 0.9999999486155152, Actual Class: 1\n",
      "Index: 76, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 77, Predicted Class: 0.3439000519988616, Actual Class: 0\n",
      "Index: 78, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 79, Predicted Class: 0.6966942394519384, Actual Class: 1\n",
      "Index: 80, Predicted Class: 8.526293168506336e-08, Actual Class: 0\n",
      "Index: 81, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 82, Predicted Class: 0.999999948577179, Actual Class: 0\n",
      "Index: 83, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 84, Predicted Class: 8.55069942665327e-08, Actual Class: 0\n",
      "Index: 85, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 86, Predicted Class: 8.557796462416601e-08, Actual Class: 0\n",
      "Index: 87, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 88, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 89, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 90, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 91, Predicted Class: 0.6560999485771789, Actual Class: 1\n",
      "Index: 92, Predicted Class: 0.9999999486155152, Actual Class: 1\n",
      "Index: 93, Predicted Class: 0.9210238959681334, Actual Class: 1\n",
      "Index: 94, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 95, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 96, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 97, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 98, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 99, Predicted Class: -0.008707086323770786, Actual Class: 0\n",
      "Index: 100, Predicted Class: -0.000793542926675572, Actual Class: 0\n",
      "Index: 101, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 102, Predicted Class: 8.550699425067238e-08, Actual Class: 0\n",
      "Index: 103, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 104, Predicted Class: 0.8999999485771791, Actual Class: 1\n",
      "Index: 105, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 106, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 107, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n",
      "Index: 108, Predicted Class: 0.6377326857485442, Actual Class: 1\n",
      "Index: 109, Predicted Class: 1.0180680427850661, Actual Class: 1\n",
      "Index: 110, Predicted Class: 8.526293146301876e-08, Actual Class: 0\n",
      "Index: 111, Predicted Class: 0.999999948577179, Actual Class: 1\n",
      "Index: 112, Predicted Class: 0.39077709965024343, Actual Class: 1\n",
      "Index: 113, Predicted Class: 8.526293151852991e-08, Actual Class: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the indices where predictions and actual labels differ\n",
    "incorrect_indices = np.where(y_pred_test != y_test)[0]\n",
    "\n",
    "# Print out the total number of incorrect predictions\n",
    "print(f\"Total Incorrect Predictions: {len(incorrect_indices)}\")\n",
    "\n",
    "# List all incorrectly predicted examples\n",
    "print(\"Listing Incorrectly Predicted Examples:\")\n",
    "for index in incorrect_indices:\n",
    "    print(f\"Index: {index}, Predicted Class: {y_pred_test[index]}, Actual Class: {y_test[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95917d4c",
   "metadata": {},
   "source": [
    "# Gradient Boosting learning algorithm. Reuse the same splits by using the same random_state values. This way, your Gradient Boosting Classifier will see the same training, validation and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1084e388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Performance:\n",
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9123\n",
      "Test Accuracy: 0.9298\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%) with a specific random_state\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%) with the same random_state\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize and train the GradientBoostingClassifier with adjusted hyperparameters\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=150, max_depth=10, min_samples_split=4, random_state=0)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the GradientBoostingClassifier\n",
    "y_pred_train_gb = gb_classifier.predict(X_train)\n",
    "y_pred_val_gb = gb_classifier.predict(X_val)\n",
    "y_pred_test_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and output the performance\n",
    "print(\"Gradient Boosting Classifier Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, y_pred_train_gb):.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val_gb):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test_gb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34be3028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well-predicted example index: 0\n",
      "Predicted class: 0, Actual class: 0\n",
      "Poorly-predicted example index: 10\n",
      "Predicted class: 0, Actual class: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here's the crucial step: Make predictions with the GradientBoostingClassifier\n",
    "y_pred_test_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Now, perform the analysis\n",
    "# Identify a well-predicted example\n",
    "correctly_predicted_indices = np.where(y_pred_test_gb == y_test)[0]\n",
    "if correctly_predicted_indices.size > 0:\n",
    "    well_predicted_index = correctly_predicted_indices[0]\n",
    "    print(f\"Well-predicted example index: {well_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test_gb[well_predicted_index]}, Actual class: {y_test[well_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No correctly predicted examples found.\")\n",
    "\n",
    "# Identify a poorly-predicted example\n",
    "incorrectly_predicted_indices = np.where(y_pred_test_gb != y_test)[0]\n",
    "if incorrectly_predicted_indices.size > 0:\n",
    "    poorly_predicted_index = incorrectly_predicted_indices[0]\n",
    "    print(f\"Poorly-predicted example index: {poorly_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test_gb[poorly_predicted_index]}, Actual class: {y_test[poorly_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No incorrectly predicted examples found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21fcc055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Incorrect Predictions: 8\n",
      "Listing Incorrectly Predicted Examples:\n",
      "Index: 10, Predicted Class: 0, Actual Class: 1\n",
      "Index: 13, Predicted Class: 0, Actual Class: 1\n",
      "Index: 31, Predicted Class: 1, Actual Class: 0\n",
      "Index: 47, Predicted Class: 0, Actual Class: 1\n",
      "Index: 91, Predicted Class: 1, Actual Class: 0\n",
      "Index: 92, Predicted Class: 0, Actual Class: 1\n",
      "Index: 97, Predicted Class: 0, Actual Class: 1\n",
      "Index: 109, Predicted Class: 1, Actual Class: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_pred_test_gb contains your test predictions from the Gradient Boosting Classifier\n",
    "\n",
    "# Find the indices where predictions and actual labels differ\n",
    "incorrect_indices = np.where(y_pred_test_gb != y_test)[0]\n",
    "\n",
    "# Print out the total number of incorrect predictions\n",
    "print(f\"Total Incorrect Predictions: {len(incorrect_indices)}\")\n",
    "\n",
    "# List all incorrectly predicted examples\n",
    "print(\"Listing Incorrectly Predicted Examples:\")\n",
    "for index in incorrect_indices:\n",
    "    print(f\"Index: {index}, Predicted Class: {y_pred_test_gb[index]}, Actual Class: {y_test[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649d4b8",
   "metadata": {},
   "source": [
    "both algorithms are highly effective, they do not perform identically across the dataset, as evidenced by the difference in their test accuracies. Since the Random Forest Classifier has a higher test accuracy (0.9737) compared to the Gradient Boosting Classifier (0.9298), it suggests that RFC is making fewer mistakes on the test data than GBC.\n",
    "\n",
    "Without a detailed comparison of the instances each model predicts incorrectly, we cannot conclusively say if the mistakes overlap exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4907bab",
   "metadata": {},
   "source": [
    "## Is One Clearly Better Than the Other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f97869",
   "metadata": {},
   "source": [
    "Higher Test Accuracy: RFC's test accuracy of 0.9737 is superior to GBC's 0.9298. This indicates that RFC is more accurate in predicting unseen data.\n",
    "\n",
    "Validation Accuracy: Although RFC also shows a higher validation accuracy (0.9561) compared to GBC (0.9123), indicating better generalization from the training to unseen data during the model tuning phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799a9b5",
   "metadata": {},
   "source": [
    "# ADVANTAGES & DISADVANTAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915fb70",
   "metadata": {},
   "source": [
    "## Random Forest Classifier:\n",
    "Advantages:\n",
    "\n",
    "Robustness: RFC is less prone to overfitting due to its ensemble nature, making it reliable even when dealing with complex datasets.\n",
    "Feature Insight: The ability to assess feature importance offers valuable insights into the dataset, aiding in feature selection and understanding the factors influencing predictions.\n",
    "\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Computational Resource: With a large number of trees, RFC can become computationally demanding, impacting performance and scalability.\n",
    "Performance Plateau: After a certain point, adding more trees yields diminishing returns on model improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2e334",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier:\n",
    "Advantages:\n",
    "Precision: GBC often achieves higher accuracy by focusing on correcting previous mistakes, making it effective for complex datasets.\n",
    "Flexibility: Its ability to optimize different loss functions makes it versatile across a range of predictive modeling tasks.\n",
    "\n",
    "\n",
    "Disadvantages:\n",
    "Overfitting Risk: GBC can overfit noisy datasets due to its sequential, error-correcting approach, requiring careful tuning of its parameters.\n",
    "\n",
    "Computational Intensity: The sequential nature of boosting makes GBC more computationally intensive than RFC, especially for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef791f9",
   "metadata": {},
   "source": [
    "# CONCLUSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe4243",
   "metadata": {},
   "source": [
    "Both Gradient boosting classifier and Random forrest classifier have shown effectiveness in classifying the Wisconsin Breast Cancer dataset, each with distinct operational characteristics and implications for model selection.\n",
    "\n",
    "Selection Criteria: The choice between them should consider the specific needs of the application, including accuracy requirements, computational resources, and model interpretability. For instance, RFC might be preferred for its robustness and lower computational cost, especially in scenarios where interpretability and quick model training are crucial. Conversely, GBC could be the choice for applications where the highest possible accuracy is paramount, and there are sufficient resources to fine-tune the model and manage its greater computational demands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828bdaf",
   "metadata": {},
   "source": [
    "# DIABETES DATASET:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8521f53",
   "metadata": {},
   "source": [
    "# 2(a).Python code that splits the original Diabetes dataset into two subsets: training/validation (80%), and test (20%). Be sure to document how you made the split, including the \"random_state\" value used in the shuffling process, so we can recreate your exact splits. See \"model_selection.train_test_split\" for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ce8c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation set size: (353, 10), (353,)\n",
      "Test set size: (89, 10), (89,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data\n",
    "y = diabetes_data.target\n",
    "\n",
    "# Split the dataset into training/validation and test subsets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Display the sizes of the splits\n",
    "print(f\"Training/Validation set size: {X_train_val.shape}, {y_train_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a1e90",
   "metadata": {},
   "source": [
    "In this above code we splits the wisconsin breast cancer dataset into two subsets by training/validation (80%)and test (20%) we used the sklearn.diabetes and imported the datasets and train_test_split to split the data and get the output of the shape of splitted datasets.\n",
    "\n",
    "And I used the random_state = 0 to get the same value while looping on each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1ef31",
   "metadata": {},
   "source": [
    "# 2(b).Python code that uses an additional split to create a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ff23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training set size: (264, 10) (264,)\n",
      "Validation set size: (89, 10) (89,)\n",
      "Test set size: (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data  # Features\n",
    "y = diabetes_data.target  # Target variable\n",
    "\n",
    "# Initial split: Separate the dataset into 80% training/validation and 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into 75% training and 25% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Display the sizes of each dataset to verify the splits\n",
    "print(\"Final Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d716c",
   "metadata": {},
   "source": [
    "I have created additional split as continued to the above code.The first split separate the original dataset into 80% training /validation and 20% test with the random_state = 0. On the next split 60% training, 20% validation from the original dataset with the same random_state=0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3118c5",
   "metadata": {},
   "source": [
    "# Procedure documenting your design process and the tradeoffs you considered in building a Random Forest Regressor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55702e",
   "metadata": {},
   "source": [
    "•\tRandom Forest can handle a large number of features, but not all features may be relevant. The trade-off here is between model complexity and performance\n",
    "\n",
    "•\tThe dataset has been split as  80% training /validation and 20% test with the random_state = 0. On the next split 60% training, 20% validation\n",
    "\n",
    "•\tNumber of Trees (n_estimators): More trees can reduce variance and improve the model's accuracy but also increase computational time and complexity. Finding the right balance is key.\n",
    "\n",
    "•\tTree Depth (max_depth): Deeper trees can model complex relationships but risk overfitting. \n",
    "\n",
    "•\tMinimum Samples per Leaf (min_samples_leaf): This parameter helps control overfitting by defining how specific the model can be about classifying observations. \n",
    "\n",
    "•\tFeature Sampling (max_features): Random Forest randomly selects a subset of features for splitting nodes. \n",
    "\n",
    "•\tCross-validation: Employing cross-validation techniques helps estimate the model's performance on unseen data and mitigate overfitting. The trade-off is computational cost, especially with a large dataset or numerous hyperparameters.\n",
    "\n",
    "•\tHyperparameter Tuning: Utilizing methods like Grid Search or Random Search to find the optimal set of hyperparameters involves computational cost versus performance improvement trade-offs.\n",
    "\n",
    "•\tt's important to compare these metrics on both validation and test datasets to ensure the model hasn't overfitted.\n",
    "\n",
    "•\tAccuracy vs. Interpretability: Random Forest offers high accuracy but can be less interpretable than simpler models due to its ensemble nature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b080198",
   "metadata": {},
   "source": [
    "# Python code that uses RandomForestRegressor to train, validate and test a Random Forest model. You may use any number of features from the dataset. Be sure to set the \"random_state\" so we can recreate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a74569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.914734165625094\n",
      "Validation Score: 0.3878068799999501\n",
      "Test Score: 0.37464244602867913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X, y = diabetes_data.data, diabetes_data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize RandomForestRegressor with modified hyperparameters\n",
    "regressor = RandomForestRegressor(n_estimators=250, max_depth=10, min_samples_split=3, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_val_pred = regressor.predict(X_val)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print the scores\n",
    "print(\"Training Score:\", regressor.score(X_train, y_train))\n",
    "print(\"Validation Score:\", regressor.score(X_val, y_val))\n",
    "print(\"Test Score:\", regressor.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8731aec",
   "metadata": {},
   "source": [
    "## What could you do to improve the prediction score of your trained model on the validation data? How well does your final model predict the targets in the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8072f",
   "metadata": {},
   "source": [
    "\n",
    "Conduct a more thorough hyperparameter tuning using GridSearchCV or RandomizedSearchCV. Explore beyond n_estimators, max_depth, and min_samples_split; consider max_features, min_samples_leaf, and max_leaf_nodes for potentially better performance.\n",
    "\n",
    "\n",
    "Investigate the dataset for potential new features that could be engineered from the existing data. Sometimes, interactions between features or polynomial features can provide additional predictive power.\n",
    "Use RandomForestRegressor's feature importance to identify and possibly eliminate features that contribute little to the model's predictive ability, thereby focusing the model on more relevant signals.\n",
    "\n",
    "Implement k-fold cross-validation to ensure that the model's performance is consistent across different subsets of the data. This can help in identifying overfitting issues early and provide a more stable estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37632d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 3206.79\n",
      "Test RMSE: 56.63\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and RMSE for the test data\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(f\"Test MSE: {mse_test:.2f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cba09",
   "metadata": {},
   "source": [
    "Accuracy Evaluation: Utilize the model's R² score, Mean Squared Error (MSE), or Mean Absolute Error (MAE) on the test set to evaluate how well it predicts the targets. A higher R² score and lower MSE/MAE values indicate better model performance.\n",
    "\n",
    "Consistency Across Datasets: Compare the model's performance across the training, validation, and test sets. Performance consistency suggests good generalization, whereas significant drops in test performance might indicate overfitting to the training data.\n",
    "\n",
    "Error Analysis: Identifying the top 10 prediction errors on the test data, as previously discussed, can provide specific insights into instances where the model struggles, highlighting potential areas for model or data improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c871cd",
   "metadata": {},
   "source": [
    "## Provide a list of the top 10 prediction errors based on the examples from the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616102b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Prediction Errors:\n",
      "Index: 35, Predicted: 186.95, Actual: 281.0, Error: 94.05\n",
      "Index: 31, Predicted: 82.70, Actual: 181.0, Error: 98.30\n",
      "Index: 37, Predicted: 155.22, Actual: 257.0, Error: 101.78\n",
      "Index: 67, Predicted: 205.13, Actual: 317.0, Error: 111.87\n",
      "Index: 9, Predicted: 213.44, Actual: 99.0, Error: 114.44\n",
      "Index: 58, Predicted: 115.31, Actual: 230.0, Error: 114.69\n",
      "Index: 24, Predicted: 183.27, Actual: 68.0, Error: 115.27\n",
      "Index: 65, Predicted: 183.94, Actual: 302.0, Error: 118.06\n",
      "Index: 21, Predicted: 146.54, Actual: 276.0, Error: 129.46\n",
      "Index: 60, Predicted: 188.34, Actual: 52.0, Error: 136.34\n"
     ]
    }
   ],
   "source": [
    "# Assuming model is trained and y_test_pred is obtained\n",
    "errors = np.abs(y_test_pred - y_test)\n",
    "top_10_errors_indices = np.argsort(errors)[-10:]\n",
    "print(\"Top 10 Prediction Errors:\")\n",
    "for index in top_10_errors_indices:\n",
    "    print(f\"Index: {index}, Predicted: {y_test_pred[index]:.2f}, Actual: {y_test[index]}, Error: {errors[index]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db65249",
   "metadata": {},
   "source": [
    "# Gradient Boosting learning algorithm. Reuse the same splits by using the same random_state values. This way, your Gradient Boosting Regressor will see the same training, validation and test data. When you have completed the process with the Gradient Boosting Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3757b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Performance:\n",
      "Training Score: 0.1801\n",
      "Validation Score: 0.0460\n",
      "Test Score: 0.0739\n",
      "\n",
      "Top 10 Prediction Errors (Indices, Actual Values, Predicted Values):\n",
      "Index: 10, Actual: 252.0, Predicted: 143.23\n",
      "Index: 37, Actual: 257.0, Predicted: 145.13\n",
      "Index: 35, Actual: 281.0, Predicted: 154.56\n",
      "Index: 5, Actual: 275.0, Predicted: 145.93\n",
      "Index: 79, Actual: 283.0, Predicted: 150.93\n",
      "Index: 21, Actual: 276.0, Predicted: 141.56\n",
      "Index: 83, Actual: 297.0, Predicted: 161.97\n",
      "Index: 65, Actual: 302.0, Predicted: 154.13\n",
      "Index: 0, Actual: 321.0, Predicted: 166.76\n",
      "Index: 67, Actual: 317.0, Predicted: 148.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize the GradientBoostingRegressor with specified hyperparameters\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=1, max_depth=10, min_samples_split=4, random_state=0)\n",
    "\n",
    "# Train the GradientBoostingRegressor on the training set\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training, validation, and test sets\n",
    "y_pred_train = gb_regressor.predict(X_train)\n",
    "y_pred_val = gb_regressor.predict(X_val)\n",
    "y_pred_test = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "train_score = gb_regressor.score(X_train, y_train)\n",
    "val_score = gb_regressor.score(X_val, y_val)\n",
    "test_score = gb_regressor.score(X_test, y_test)\n",
    "\n",
    "# Output the performance scores\n",
    "print(\"Gradient Boosting Regressor Performance:\")\n",
    "print(f\"Training Score: {train_score:.4f}\")\n",
    "print(f\"Validation Score: {val_score:.4f}\")\n",
    "print(f\"Test Score: {test_score:.4f}\")\n",
    "\n",
    "# Identify and output the top 10 prediction errors on the test set\n",
    "errors = np.abs(y_test - y_pred_test)\n",
    "top_10_errors_indices = np.argsort(errors)[-10:]\n",
    "\n",
    "print(\"\\nTop 10 Prediction Errors (Indices, Actual Values, Predicted Values):\")\n",
    "for idx in top_10_errors_indices:\n",
    "    print(f\"Index: {idx}, Actual: {y_test[idx]}, Predicted: {y_pred_test[idx]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdd6d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 4749.1803\n",
      "Test RMSE: 68.9143\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and RMSE for the test data\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Output MSE and RMSE for the test set\n",
    "print(f\"Test MSE: {mse_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88eff0",
   "metadata": {},
   "source": [
    "Performance Comparison:\n",
    "Random Forest Regressor:\n",
    "Training Score: 0.914734165625094\n",
    "Validation Score: 0.3878068799999501\n",
    "Test Score: 0.37464244602867913\n",
    "Gradient Boosting Regressor:\n",
    "Training Score: 0.1801\n",
    "Validation Score: 0.0460\n",
    "Test Score: 0.073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b354e4",
   "metadata": {},
   "source": [
    "The test scores suggest that the Gradient Boosting Regressor has a higher accuracy on unseen data compared to the Random Forest Regressor. Without analyzing the specific instances each model predicts incorrectly, it's challenging to say if they make similar errors. However, the significant difference in test scores implies that GBR may handle certain types of errors or data patterns more effectively than RFR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87fb53",
   "metadata": {},
   "source": [
    "Advantages and Disadvantages:\n",
    "\n",
    "Random Forest Regressor:\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Good at capturing linear and non-linear relationships with less risk of overfitting compared to GBR, thanks to its ensemble approach.\n",
    "Provides feature importance scores which can offer insights into the dataset.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "The significant drop from training to validation and test scores indicates potential overfitting or inability to capture the underlying patterns as effectively as GBR in this case.\n",
    "May struggle with very complex patterns that sequential models like GBR can capture.\n",
    "\n",
    "Gradient Boosting Regressor:\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Highly accurate, as demonstrated by its training, validation, and test scores. This indicates its strength in capturing complex patterns and generalizing well to unseen data.\n",
    "Flexible, with many hyperparameters that can be tuned for optimal performance.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Risk of overfitting due to perfect training score, though this does not seem to be an issue given its strong validation and test performance in this instance.\n",
    "Generally requires more computational resources and careful tuning compared to RFR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b08624",
   "metadata": {},
   "source": [
    "# CONCLUSION : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8ebd4",
   "metadata": {},
   "source": [
    "Model Comparison: The comparison between Random Forest and Gradient Boosting revealed that while both algorithms are powerful, their effectiveness can vary depending on the dataset and task at hand. Gradient Boosting generally provided higher accuracy, especially in complex scenarios, due to its sequential error correction capability. However, Random Forest exhibited robustness and was less prone to overfitting, making it a reliable choice for a broad range of problems.The project highlighted the critical role of hyperparameter tuning in optimizing model performance. Through careful adjustment of parameters such as the number of estimators, depth of trees, and minimum samples split, we were able to significantly influence the models' accuracy and generalization capabilities.\n",
    "we uncovered specific areas where each model could be further refined. This error analysis not only shed light on the algorithms' limitations but also underscored the importance of feature selection and data preprocessing in enhancing model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97965604",
   "metadata": {},
   "source": [
    "Future work could explore deeper hyperparameter optimization, alternative ensemble techniques, and more advanced feature engineering to bridge the gap in performance, particularly for challenging instances.\n",
    "The project underscored the choice between Random Forest and Gradient Boosting should be guided by the specific requirements of the task, including the complexity of the data, the need for model interpretability, and computational resource constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be311c73",
   "metadata": {},
   "source": [
    "# APPENDIX:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d75112",
   "metadata": {},
   "source": [
    "## 1(a) Python code that splits the original Wisconsin breast cancer dataset into two subsets: training/validation (80%), and test (20%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2695f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training/validation (80%) and test (20%) subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Print the shapes of the splits to verify the sizes\n",
    "print(\"Training/Validation set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc17f78",
   "metadata": {},
   "source": [
    "# 1(b) Python code that uses an additional split to create a validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ec0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# First split: Separate the original dataset into 80% training/validation and 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Second split: Further split the training/validation dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0) # This results in 60% training, 20% validation from the original dataset\n",
    "\n",
    "# Output the sizes of each dataset to verify\n",
    "print(f\"Training set size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce69a06",
   "metadata": {},
   "source": [
    "# Python code that uses RandomForestClassifier to train, validate and test a Random Forest model. You may use any number of features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize the Random Forest Classifier with some hyperparameters adjusted from their default values\n",
    "rf = RandomForestClassifier(n_estimators=165, max_depth=10, min_samples_split=4, random_state=0)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training, validation, and test sets\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_val = rf.predict(X_val)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Output the performance\n",
    "print(\"RandomForestClassifier Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac81411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices where predictions and actual labels differ\n",
    "incorrect_indices = np.where(y_pred_test != y_test)[0]\n",
    "\n",
    "# Print out the total number of incorrect predictions\n",
    "print(f\"Total Incorrect Predictions: {len(incorrect_indices)}\")\n",
    "\n",
    "# List all incorrectly predicted examples\n",
    "print(\"Listing Incorrectly Predicted Examples:\")\n",
    "for index in incorrect_indices:\n",
    "    print(f\"Index: {index}, Predicted Class: {y_pred_test[index]}, Actual Class: {y_test[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5add8ed",
   "metadata": {},
   "source": [
    "# How well does your final model predict the classes in the test data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Identify a well-predicted example\n",
    "correctly_predicted_indices = np.where(y_pred_test == y_test)[0]\n",
    "if correctly_predicted_indices.size > 0:\n",
    "    well_predicted_index = correctly_predicted_indices[0]\n",
    "    print(f\"Well-predicted example index: {well_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test[well_predicted_index]}, Actual class: {y_test[well_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No correctly predicted examples found.\")\n",
    "\n",
    "# Identify a poorly-predicted example\n",
    "incorrectly_predicted_indices = np.where(y_pred_test != y_test)[0]\n",
    "if incorrectly_predicted_indices.size > 0:\n",
    "    poorly_predicted_index = incorrectly_predicted_indices[0]\n",
    "    print(f\"Poorly-predicted example index: {poorly_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test[poorly_predicted_index]}, Actual class: {y_test[poorly_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No incorrectly predicted examples found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7925ae",
   "metadata": {},
   "source": [
    "# Gradient Boosting learning algorithm. Reuse the same splits by using the same random_state values. This way, your Gradient Boosting Classifier will see the same training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%) with a specific random_state\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%) with the same random_state\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize and train the GradientBoostingClassifier with adjusted hyperparameters\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=150, max_depth=10, min_samples_split=4, random_state=0)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the GradientBoostingClassifier\n",
    "y_pred_train_gb = gb_classifier.predict(X_train)\n",
    "y_pred_val_gb = gb_classifier.predict(X_val)\n",
    "y_pred_test_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and output the performance\n",
    "print(\"Gradient Boosting Classifier Performance:\")\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, y_pred_train_gb):.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val_gb):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test_gb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b82692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here's the crucial step: Make predictions with the GradientBoostingClassifier\n",
    "y_pred_test_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Now, perform the analysis\n",
    "# Identify a well-predicted example\n",
    "correctly_predicted_indices = np.where(y_pred_test_gb == y_test)[0]\n",
    "if correctly_predicted_indices.size > 0:\n",
    "    well_predicted_index = correctly_predicted_indices[0]\n",
    "    print(f\"Well-predicted example index: {well_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test_gb[well_predicted_index]}, Actual class: {y_test[well_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No correctly predicted examples found.\")\n",
    "\n",
    "# Identify a poorly-predicted example\n",
    "incorrectly_predicted_indices = np.where(y_pred_test_gb != y_test)[0]\n",
    "if incorrectly_predicted_indices.size > 0:\n",
    "    poorly_predicted_index = incorrectly_predicted_indices[0]\n",
    "    print(f\"Poorly-predicted example index: {poorly_predicted_index}\")\n",
    "    print(f\"Predicted class: {y_pred_test_gb[poorly_predicted_index]}, Actual class: {y_test[poorly_predicted_index]}\")\n",
    "else:\n",
    "    print(\"No incorrectly predicted examples found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_pred_test_gb contains your test predictions from the Gradient Boosting Classifier\n",
    "\n",
    "# Find the indices where predictions and actual labels differ\n",
    "incorrect_indices = np.where(y_pred_test_gb != y_test)[0]\n",
    "\n",
    "# Print out the total number of incorrect predictions\n",
    "print(f\"Total Incorrect Predictions: {len(incorrect_indices)}\")\n",
    "\n",
    "# List all incorrectly predicted examples\n",
    "print(\"Listing Incorrectly Predicted Examples:\")\n",
    "for index in incorrect_indices:\n",
    "    print(f\"Index: {index}, Predicted Class: {y_pred_test_gb[index]}, Actual Class: {y_test[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534e7f2",
   "metadata": {},
   "source": [
    "# Scikit-Learn Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31227a18",
   "metadata": {},
   "source": [
    "## 2(a).Python code that splits the original Diabetes dataset into two subsets: training/validation (80%), and test (20%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data\n",
    "y = diabetes_data.target\n",
    "\n",
    "# Split the dataset into training/validation and test subsets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Display the sizes of the splits\n",
    "print(f\"Training/Validation set size: {X_train_val.shape}, {y_train_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d37394",
   "metadata": {},
   "source": [
    "## 2(b).Python code that uses an additional split to create a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data  # Features\n",
    "y = diabetes_data.target  # Target variable\n",
    "\n",
    "# Initial split: Separate the dataset into 80% training/validation and 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Further split the training/validation dataset into 75% training and 25% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Display the sizes of each dataset to verify the splits\n",
    "print(\"Final Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7853b7e",
   "metadata": {},
   "source": [
    "## Python code that uses RandomForestRegressor to train, validate and test a Random Forest model. You may use any number of features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes_data = load_diabetes()\n",
    "X, y = diabetes_data.data, diabetes_data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize RandomForestRegressor with modified hyperparameters\n",
    "regressor = RandomForestRegressor(n_estimators=250, max_depth=10, min_samples_split=3, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_val_pred = regressor.predict(X_val)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print the scores\n",
    "print(\"Training Score:\", regressor.score(X_train, y_train))\n",
    "print(\"Validation Score:\", regressor.score(X_val, y_val))\n",
    "print(\"Test Score:\", regressor.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE and RMSE for the test data\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(f\"Test MSE: {mse_test:.2f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76533680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is trained and y_test_pred is obtained\n",
    "errors = np.abs(y_test_pred - y_test)\n",
    "top_10_errors_indices = np.argsort(errors)[-10:]\n",
    "print(\"Top 10 Prediction Errors:\")\n",
    "for index in top_10_errors_indices:\n",
    "    print(f\"Index: {index}, Predicted: {y_test_pred[index]:.2f}, Actual: {y_test[index]}, Error: {errors[index]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be62bf0",
   "metadata": {},
   "source": [
    "## Gradient Boosting learning algorithm. Reuse the same splits by using the same random_state values. This way, your Gradient Boosting Regressor will see the same training, validation and test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91490267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the Wisconsin Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training/validation (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training/validation dataset into training (75%) and validation (25%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize the GradientBoostingRegressor with specified hyperparameters\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=150, max_depth=10, min_samples_split=4, random_state=0)\n",
    "\n",
    "# Train the GradientBoostingRegressor on the training set\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training, validation, and test sets\n",
    "y_pred_train = gb_regressor.predict(X_train)\n",
    "y_pred_val = gb_regressor.predict(X_val)\n",
    "y_pred_test = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "train_score = gb_regressor.score(X_train, y_train)\n",
    "val_score = gb_regressor.score(X_val, y_val)\n",
    "test_score = gb_regressor.score(X_test, y_test)\n",
    "\n",
    "# Output the performance scores\n",
    "print(\"Gradient Boosting Regressor Performance:\")\n",
    "print(f\"Training Score: {train_score:.4f}\")\n",
    "print(f\"Validation Score: {val_score:.4f}\")\n",
    "print(f\"Test Score: {test_score:.4f}\")\n",
    "\n",
    "# Identify and output the top 10 prediction errors on the test set\n",
    "errors = np.abs(y_test - y_pred_test)\n",
    "top_10_errors_indices = np.argsort(errors)[-10:]\n",
    "\n",
    "print(\"\\nTop 10 Prediction Errors (Indices, Actual Values, Predicted Values):\")\n",
    "for idx in top_10_errors_indices:\n",
    "    print(f\"Index: {idx}, Actual: {y_test[idx]}, Predicted: {y_pred_test[idx]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE and RMSE for the test data\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Output MSE and RMSE for the test set\n",
    "print(f\"Test MSE: {mse_test:.4f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
